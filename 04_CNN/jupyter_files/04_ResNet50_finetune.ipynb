{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d7d24c-a45c-4e09-8ead-575c83ff8789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ResNet-50 Architecture\n",
    "+----------+------------------+--------------------------------+------------------+\n",
    "| Layer    | Type             | Configuration                  | Output Size      |\n",
    "+----------+------------------+--------------------------------+------------------+\n",
    "| Input    | Image            | 224 x 224 x 3 (RGB)            | 224 x 224 x 3    |\n",
    "|          |                  |                                |                  |\n",
    "| Conv1    | Convolution      | 64 filters (7x7), Stride 2     | 112 x 112 x 64   |\n",
    "| BN1      | Batch Norm       | -                              | 112 x 112 x 64   |\n",
    "| ReLU     | Activation       | -                              | 112 x 112 x 64   |\n",
    "| MaxPool  | Max Pooling      | 3x3 window, Stride 2           | 56 x 56 x 64     |\n",
    "|          |                  |                                |                  |\n",
    "| Stage 1  | Residual Block 1 | [1x1,64] [3x3,64] [1x1,256] ×3 | 56 x 56 x 256    |\n",
    "|          |                  | + Skip Connection              |                  |\n",
    "|          |                  |                                |                  |\n",
    "| Stage 2  | Residual Block 2 | [1x1,128][3x3,128][1x1,512] ×4 | 28 x 28 x 512    |\n",
    "|          |                  | + Skip Connection (stride 2)   |                  |\n",
    "|          |                  |                                |                  |\n",
    "| Stage 3  | Residual Block 3 | [1x1,256][3x3,256][1x1,1024]×6 | 14 x 14 x 1024   |\n",
    "|          |                  | + Skip Connection (stride 2)   |                  |\n",
    "|          |                  |                                |                  |\n",
    "| Stage 4  | Residual Block 4 | [1x1,512][3x3,512][1x1,2048]×3 | 7 x 7 x 2048     |\n",
    "|          |                  | + Skip Connection (stride 2)   |                  |\n",
    "|          |                  |                                |                  |\n",
    "| AvgPool  | Global Avg Pool  | 7x7 window                     | 1 x 1 x 2048     |\n",
    "| Flatten  | Flatten          | -                              | 2048             |\n",
    "| FC       | Fully Connected  | 1000 Neurons (Softmax)         | 1000             |\n",
    "+----------+------------------+--------------------------------+------------------+\n",
    "\n",
    "Residual Block (Bottleneck) Structure:\n",
    "┌─────────────────────────────────────────────────┐\n",
    "│  Input (x)                                      │\n",
    "│    │                                            │\n",
    "│    ├──────────────────────────┐                 │\n",
    "│    │                          │                 │\n",
    "│    ▼                          │ (Skip/Identity) │\n",
    "│  1x1 Conv → BN → ReLU         │                 │\n",
    "│    │                          │                 │\n",
    "│    ▼                          │                 │\n",
    "│  3x3 Conv → BN → ReLU         │                 │\n",
    "│    │                          │                 │\n",
    "│    ▼                          │                 │\n",
    "│  1x1 Conv → BN                │                 │\n",
    "│    │                          │                 │\n",
    "│    └──────────► ADD ◄─────────┘                 │\n",
    "│                 │                               │\n",
    "│                 ▼                               │\n",
    "│               ReLU                              │\n",
    "│                 │                               │\n",
    "│              Output                             │\n",
    "└─────────────────────────────────────────────────┘\n",
    "\n",
    "Key Characteristics of ResNet:\n",
    "\n",
    "- Residual/Skip Connections: The core innovation - adds input directly to output\n",
    "  F(x) + x instead of just F(x), solving the degradation problem\n",
    "  \n",
    "- Bottleneck Design: Uses 1x1 convolutions to reduce/restore dimensions, making\n",
    "  the network more efficient (1x1 reduces → 3x3 processes → 1x1 expands)\n",
    "  \n",
    "- Batch Normalization: Applied after every convolutional layer before activation\n",
    "\n",
    "- No Dropout: ResNet doesn't use dropout; residual connections provide \n",
    "  regularization effect\n",
    "  \n",
    "- Identity Mapping: When dimensions change, uses 1x1 convolutions to match \n",
    "  dimensions for the skip connection\n",
    "\n",
    "- Depth Variants: ResNet-18, ResNet-34 (basic blocks), ResNet-50, ResNet-101, \n",
    "  ResNet-152 (bottleneck blocks)\n",
    "\n",
    "- Total Parameters: ~25.6 million (ResNet-50)\n",
    "\n",
    "The skip connections allow gradients to flow directly through the network during\n",
    "backpropagation, enabling training of very deep networks (100+ layers) without\n",
    "degradation. The network learns residual functions F(x) = H(x) - x rather than\n",
    "directly learning H(x), which is easier to optimize.\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb8d60-6249-46a9-8288-529ab524a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## ResNet50 building ##\n",
    "#######################\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck residual block for ResNet50 (The block is called \"bottleneck\" because it reduces then expands channels\n",
    "    Architecture: 1x1 -> 3x3 -> 1x1 with skip connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Main path: Three convolutions: 1x1 → 3x3 → 1x1\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Skip connection (identity or projection)\n",
    "        self.downsample = downsample # For matching dimensions\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x # Save original input for skip connection\n",
    "        \n",
    "        # Main path: Learns F(x) (the transformations)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        # Skip connection: Adds original input x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x) # Match dimensions if needed\n",
    "        \n",
    "        out += identity  # ⭐ ADD skip connectio, out = F(x) + x, this is the key innovation!\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial layers: Conv1 -> BN -> ReLU -> MaxPool\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        # Conv2_x: 3 bottleneck blocks (64->64->256)\n",
    "        self.conv2_x = self._make_layer(in_channels=64, mid_channels=64, out_channels=256, num_blocks=3, stride=1)\n",
    "        \n",
    "        # Conv3_x: 4 bottleneck blocks (128->128->512)\n",
    "        self.conv3_x = self._make_layer(in_channels=256, mid_channels=128, out_channels=512, num_blocks=4, stride=2)\n",
    "        \n",
    "        # Conv4_x: 6 bottleneck blocks (256->256->1024)\n",
    "        self.conv4_x = self._make_layer(in_channels=512, mid_channels=256, out_channels=1024, num_blocks=6, stride=2)\n",
    "        \n",
    "        # Conv5_x: 3 bottleneck blocks (512->512->2048)\n",
    "        self.conv5_x = self._make_layer(in_channels=1024, mid_channels=512, out_channels=2048, num_blocks=3, stride=2)\n",
    "        \n",
    "        # Final layers: AvgPool -> Flatten -> FC\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "        \n",
    "    def _make_layer(self, in_channels, mid_channels, out_channels, num_blocks, stride):\n",
    "        \"\"\"\n",
    "        Create a sequence of bottleneck blocks\n",
    "        First block may downsample, rest use identity skip connections\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        \n",
    "        # First block (may need downsampling for skip connection)\n",
    "        downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        layers.append(BottleneckBlock(in_channels, mid_channels, out_channels, stride, downsample))\n",
    "        \n",
    "        # Remaining blocks (identity skip connections)\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BottleneckBlock(out_channels, mid_channels, out_channels, stride=1, downsample=None))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.conv1(X)\n",
    "        \n",
    "        out = self.conv2_x(out)\n",
    "        out = self.conv3_x(out)\n",
    "        out = self.conv4_x(out)\n",
    "        out = self.conv5_x(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import torch\n",
    "    \n",
    "    # Create model\n",
    "    model = ResNet50(num_classes=1000)\n",
    "    \n",
    "    # Test with random input\n",
    "    x = torch.randn(1, 3, 224, 224)\n",
    "    output = model(x)\n",
    "    \n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5459c14-fa1c-49c2-94a2-72aa8ed36436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
