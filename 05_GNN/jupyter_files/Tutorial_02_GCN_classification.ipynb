{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric._datasets import  Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa14242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Dataset preparation ##\n",
    "#########################\n",
    "\n",
    "root_path = '/home/longdpt/Documents/Long_AISDL/DeepLearning_PyTorch/05_GNN/data'\n",
    "\n",
    "#---------\n",
    "## Load the dataset\n",
    "#---------\n",
    "\n",
    "dataset = Planetoid(root=root_path, name=\"Cora\")\n",
    "\n",
    "'''\n",
    "Planetoid is not a single dataset, but rather a collection of three citation network datasets, \n",
    "commonly used for benchmarking Graph Neural Networks (GNNs).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a88070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "number of graphs:\t\t 1\n",
      "number of classes:\t\t 7\n",
      "number of node features:\t 1433\n",
      "number of edge features:\t 0\n"
     ]
    }
   ],
   "source": [
    "#---------\n",
    "## Dataset properties\n",
    "#---------\n",
    "\n",
    "print(dataset) # Cora()\n",
    "print(\"number of graphs:\\t\\t\", len(dataset))                      # 1 (has only one graph)\n",
    "print(\"number of classes:\\t\\t\", dataset.num_classes)              # 7 (has 7 different features)\n",
    "print(\"number of node features:\\t\", dataset.num_node_features)    # 1433 (each node has 1433 features)\n",
    "print(\"number of edge features:\\t\", dataset.num_edge_features)    # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "\n",
      "\n",
      "edge_index:\t\t torch.Size([2, 10556])\n",
      "tensor([[ 633, 1862, 2582,  ...,  598, 1473, 2706],\n",
      "        [   0,    0,    0,  ..., 2707, 2707, 2707]])\n",
      "\n",
      "\n",
      "train_mask:\t\t torch.Size([2708])\n",
      "tensor([ True,  True,  True,  ..., False, False, False])\n",
      "\n",
      "\n",
      "X:\t\t torch.Size([2708, 1433])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "\n",
      "\n",
      "y:\t\t torch.Size([2708])\n",
      "tensor([3, 4, 4,  ..., 3, 3, 3])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------\n",
    "## dataset._data\n",
    "#---------\n",
    "\n",
    "print(dataset._data)\n",
    "print(\"\\n\")\n",
    "# Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
    "'''\n",
    "2,708 nodes (papers)\n",
    "10,556 edges (citations)\n",
    "1,433 features (words)\n",
    "7 classes (research topics)\n",
    "'''\n",
    "\n",
    "print(\"edge_index:\\t\\t\", dataset._data.edge_index.shape)\n",
    "print(dataset._data.edge_index)\n",
    "print(\"\\n\")\n",
    "# edge_index:\t\t torch.Size([2, 10556])              10556 edges (citation relationships)\n",
    "# tensor([[ 633, 1862, 2582,  ...,  598, 1473, 2706],    SOURCE NODES\n",
    "#         [   0,    0,    0,  ..., 2707, 2707, 2707]])   TARGET NODES\n",
    "# Example: 633 -> 0, 1862 -> 0\n",
    "\n",
    "print(\"train_mask:\\t\\t\", dataset._data.train_mask.shape)\n",
    "print(dataset._data.train_mask)\n",
    "print(\"\\n\")\n",
    "# train_mask:\t\t torch.Size([2708])\n",
    "# tensor([ True,  True,  True,  ..., False, False, False])\n",
    "# True: this is from the training set\n",
    "# False: this is NOT in the training set\n",
    "\n",
    "print(\"X:\\t\\t\", dataset._data.x.shape)\n",
    "print(dataset._data.x)\n",
    "print(\"\\n\")\n",
    "# X:\t\t torch.Size([2708, 1433])\n",
    "# tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         ...,\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.]])\n",
    "# Each row represents one node\n",
    "# Each column represents one feature of a node\n",
    "\n",
    "print(\"y:\\t\\t\", dataset._data.y.shape)\n",
    "print(dataset._data.y)\n",
    "print(\"\\n\")\n",
    "# y:\t\t torch.Size([2708])\n",
    "# tensor([3, 4, 4,  ..., 3, 3, 3])\n",
    "# The output label of each node (in this example, we have 7 different classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e1d921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "## get the data\n",
    "#----\n",
    "\n",
    "data = dataset[0] # Since we have only one dataset, use [0] to get it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c724f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## Simple GNN ##\n",
    "################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv # GraphSAGE Convolution layer from PyTorch Geometric\n",
    "\n",
    "'''\n",
    "What is SAGEConv?\n",
    "GraphSAGE (SAmple and aggreGatE) is a type of graph convolution that:\n",
    "# Samples neighbors of each node\n",
    "# Aggregates their features\n",
    "# Combines with the node's own features\n",
    "\n",
    "What happens inside SAGEConv:\n",
    "For each node i:\n",
    "# Gather features from neighbors: {x_j : j ∈ Neighbors(i)}\n",
    "# Aggregate: h_neighbors = max(x_j for all neighbors j) (element-wise max)\n",
    "# Combine: h_i = W * concat([x_i, h_neighbors])\n",
    "\n",
    "############ Example #############\n",
    "\n",
    "x_i = [1, 0, 1]\n",
    "\n",
    "neighbor_1 = [1, 2, 1]\n",
    "neighbor_2 = [3, 4, 2]\n",
    "neighbor_3 = [8, 1, 0]\n",
    "\n",
    "aggregated = [max(1, 3, 8),   # position 0\n",
    "              max(2, 4, 1),   # position 1\n",
    "              max(1, 2, 0)]   # position 2\n",
    "\n",
    "aggregated = [8, 4, 2]  ✅\n",
    "\n",
    "=> concat([x_i, aggregated]) = [1, 0, 1, 8, 4, 2]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Representation\n",
    "```\n",
    "Position:       0   1   2\n",
    "              ┌───┬───┬───┐\n",
    "Neighbor 1:   │ 1 │ 2 │ 1 │\n",
    "              ├───┼───┼───┤\n",
    "Neighbor 2:   │ 3 │ 4 │ 2 │\n",
    "              ├───┼───┼───┤\n",
    "Neighbor 3:   │ 8 │ 1 │ 0 │\n",
    "              ├───┼───┼───┤\n",
    "              │ ↓ │ ↓ │ ↓ │\n",
    "              ├───┼───┼───┤\n",
    "Max:          │ 8 │ 4 │ 2 │\n",
    "              └───┴───┴───┘\n",
    "              \n",
    "Node's own features:     [1, 0, 1]\n",
    "                             +\n",
    "Aggregated neighbors:    [8, 4, 2]\n",
    "                              ↓\n",
    "Concatenated:            [1, 0, 1, 8, 4, 2]\n",
    "                         └─────┘ └───────┘\n",
    "                          self   neighbors\n",
    "'''\n",
    "\n",
    "#----\n",
    "## build model\n",
    "#----\n",
    "\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = SAGEConv(\n",
    "            in_channels=dataset.num_features, # 1433 (Cora)\n",
    "            out_channels=dataset.num_classes, # 7 (Cora)\n",
    "            aggr=\"max\" # could be max, mean, add, ...\n",
    "        )\n",
    "        \n",
    "    def forward(self):\n",
    "        out = self.cnn(data.x, data.edge_index)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf380de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Optimizer ##\n",
    "###############\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model, data = SimpleGNN().to(device), data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-09 13:56:53.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 1\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.4380\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.4330\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 10\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7260\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7180\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 20\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7260\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:53.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7180\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 30\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7260\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7180\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 40\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7260\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7180\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 50\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7260\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7180\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 60\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7260\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7180\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 70\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7260\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7180\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 80\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7280\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7100\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 90\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7340\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7160\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEpoch: 100\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mVal: 0.7340\u001b[0m\n",
      "\u001b[32m2026-01-09 13:56:54.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mTest: 0.7160\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "## Training ##\n",
    "##############\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "\n",
    "for epoch in range(1, 101, 1):\n",
    "    #----TRAIN\n",
    "    _ = model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #-----VAL - TEST\n",
    "    _ = model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "        \n",
    "    _, val_acc, tmp_test_acc = accs\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "        \n",
    "    if (epoch % 10 == 0) or (epoch == 1):\n",
    "        logger.info(\"+\"*50)\n",
    "        logger.info(f\"Epoch: {epoch}\")\n",
    "        logger.info(f\"Val: {best_val_acc:.4f}\")\n",
    "        logger.info(f\"Test: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8b677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
