{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f03aa13-4e01-4ef4-8ccd-0c13fbd62c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (24_167, 5)\n",
      "┌────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ Date       ┆ Open        ┆ High        ┆ Low         ┆ Close       │\n",
      "│ ---        ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
      "│ str        ┆ f64         ┆ f64         ┆ f64         ┆ f64         │\n",
      "╞════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ 1927-12-30 ┆ 17.66       ┆ 17.66       ┆ 17.66       ┆ 17.66       │\n",
      "│ 1928-01-03 ┆ 17.76       ┆ 17.76       ┆ 17.76       ┆ 17.76       │\n",
      "│ 1928-01-04 ┆ 17.719999   ┆ 17.719999   ┆ 17.719999   ┆ 17.719999   │\n",
      "│ 1928-01-05 ┆ 17.549999   ┆ 17.549999   ┆ 17.549999   ┆ 17.549999   │\n",
      "│ 1928-01-06 ┆ 17.66       ┆ 17.66       ┆ 17.66       ┆ 17.66       │\n",
      "│ …          ┆ …           ┆ …           ┆ …           ┆ …           │\n",
      "│ 2024-03-11 ┆ 5111.959961 ┆ 5124.660156 ┆ 5091.140137 ┆ 5117.939941 │\n",
      "│ 2024-03-12 ┆ 5134.299805 ┆ 5179.870117 ┆ 5114.47998  ┆ 5175.27002  │\n",
      "│ 2024-03-13 ┆ 5173.490234 ┆ 5179.140137 ┆ 5151.879883 ┆ 5165.310059 │\n",
      "│ 2024-03-14 ┆ 5175.140137 ┆ 5176.850098 ┆ 5123.299805 ┆ 5150.47998  │\n",
      "│ 2024-03-15 ┆ 5123.310059 ┆ 5136.859863 ┆ 5104.350098 ┆ 5117.089844 │\n",
      "└────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "spx = load_dataset('misikoff/SPX', split='train')\n",
    "\n",
    "spx = spx.to_polars().select(['Date', 'Open', 'High', 'Low', 'Close'])\n",
    "\n",
    "print(spx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f46d00-bd02-4d4d-abe1-9d70aacec5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Close prices (first 5): [17.66     17.76     17.719999 17.549999 17.66    ]\n",
      "Scaled Close prices (first 5): [0.00256437 0.0025837  0.00257597 0.00254309 0.00256437]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1: PREPARE DATA\n",
    "# ============================================\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Extract Close prices\n",
    "data = spx['Close'].to_numpy()\n",
    "\n",
    "# Normalize data to [0, 1] range (LSTMs work better with normalized data)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"\\nOriginal Close prices (first 5): {data[:5]}\")\n",
    "print(f\"Scaled Close prices (first 5): {data_scaled[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b051643-68bc-4eb5-89b8-49282074f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence shape:\n",
      "X shape: (24107, 60)  # (samples, sequence_length)\n",
      "y shape: (24107,)  # (samples,)\n",
      "\n",
      "Training data shape: torch.Size([19285, 60, 1])\n",
      "Testing data shape: torch.Size([4822, 60, 1])\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 2: CREATE SEQUENCES\n",
    "# ============================================\n",
    "# Use past N days to predict next day's closing price\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Convert time series into sequences\n",
    "    Input: [17.66, 17.76, 17.72, 17.55, 17.66, ...]\n",
    "    Output: \n",
    "        X: [[17.66, 17.76, 17.72, ...], [17.76, 17.72, 17.55, ...], ...]\n",
    "        y: [next_day_close_1, next_day_close_2, ...]\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Use 60 days of data to predict next day\n",
    "SEQ_LENGTH = 60\n",
    "\n",
    "X, y = create_sequences(data_scaled, SEQ_LENGTH)\n",
    "\n",
    "print(f\"\\nSequence shape:\")\n",
    "print(f\"X shape: {X.shape}  # (samples, sequence_length)\")\n",
    "print(f\"y shape: {y.shape}  # (samples,)\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: TRAIN/TEST SPLIT\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "\n",
    "train_size = int(0.8 * len(X))\n",
    "\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "# LSTM expects input shape: (batch_size, seq_length, input_size)\n",
    "X_train = torch.FloatTensor(X_train).unsqueeze(-1)  # Add feature dimension\n",
    "X_test = torch.FloatTensor(X_test).unsqueeze(-1)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9082ca-f590-4aa9-ab51-e2d2a313ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Parameters: 50,497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longdpt/miniconda3/envs/dl/lib/python3.12/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Check device availability\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: BUILD LSTM MODEL\n",
    "# ============================================\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class StackedLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,      # 1 (Close price)\n",
    "            hidden_size=hidden_size,    # 64 hidden units\n",
    "            num_layers=num_layers,      # 2 stacked LSTM layers\n",
    "            batch_first=True,           # Input: (batch, seq, feature)\n",
    "            dropout=dropout if num_layers > 1 else 0  # Dropout between LSTM layers\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer to produce output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        # h0: (num_layers, batch_size, hidden_size)\n",
    "        # c0: (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        # out: (batch_size, seq_length, hidden_size)\n",
    "        # hn, cn: final hidden and cell states\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Get output from last time step\n",
    "        last_output = out[:, -1, :]\n",
    "        \n",
    "        # Pass through fully connected layer\n",
    "        prediction = self.fc(last_output)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "model = StackedLSTM(hidden_size=64, num_layers=2).to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return f'{sum(p.numel() for p in model.parameters()):,}'\n",
    "\n",
    "print(f\"\\nModel Parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc55578b-c519-44d1-958b-88791c4ced63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "Epoch [10/100], Loss: 0.002965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m batch_y = y_train[i:i+batch_size].to(device)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m predictions = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m.squeeze()\n\u001b[32m     23\u001b[39m loss = criterion(predictions, batch_y)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mStackedLSTM.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     35\u001b[39m c0 = torch.zeros(\u001b[38;5;28mself\u001b[39m.num_layers, x.size(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.hidden_size).to(x.device)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Forward propagate LSTM\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# out: (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# hn, cn: final hidden and cell states\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m out, (hn, cn) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Get output from last time step\u001b[39;00m\n\u001b[32m     43\u001b[39m last_output = out[:, -\u001b[32m1\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 5: TRAIN THE MODEL\n",
    "# ============================================\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "print(\"\\nTraining...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Mini-batch training\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = X_train[i:i+batch_size].to(device)\n",
    "        batch_y = y_train[i:i+batch_size].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(batch_X).squeeze()\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (helps with exploding gradients)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = epoch_loss / (len(X_train) / batch_size)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82adf0-b906-45d4-9153-9c5037758807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 6: MAKE PREDICTIONS\n",
    "# ============================================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predict on test set\n",
    "    test_predictions = model(X_test).squeeze().cpu().numpy()  # Move to CPU for numpy\n",
    "    \n",
    "    # Inverse transform\n",
    "    test_predictions_actual = scaler.inverse_transform(\n",
    "        test_predictions.reshape(-1, 1)\n",
    "    ).flatten()\n",
    "    \n",
    "    y_test_actual = scaler.inverse_transform(\n",
    "        y_test.cpu().numpy().reshape(-1, 1)  # Move to CPU\n",
    "    ).flatten()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREDICTIONS vs ACTUAL (S&P 500 Close Prices)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Day':>5} | {'Actual Close':>15} | {'Predicted Close':>15} | {'Error':>10} | {'Error %':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i in range(10):\n",
    "    actual = y_test_actual[i]\n",
    "    pred = test_predictions_actual[i]\n",
    "    error = abs(actual - pred)\n",
    "    error_pct = (error / actual) * 100\n",
    "    print(f\"{i+1:5} | {actual:15.2f} | {pred:15.2f} | {error:10.2f} | {error_pct:9.2f}%\")\n",
    "\n",
    "# Calculate metrics\n",
    "mae = np.mean(np.abs(y_test_actual - test_predictions_actual))\n",
    "mse = np.mean((y_test_actual - test_predictions_actual) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((y_test_actual - test_predictions_actual) / y_test_actual)) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Mean Absolute Error (MAE):        ${mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):   ${rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error:    {mape:.2f}%\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 7: VISUALIZE PREDICTIONS\n",
    "# ============================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_test_actual[:100], label='Actual Close Price', linewidth=2)\n",
    "plt.plot(test_predictions_actual[:100], label='Predicted Close Price', linewidth=2, alpha=0.7)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('S&P 500 Close Price ($)')\n",
    "plt.title('LSTM Stock Price Prediction - First 100 Test Days')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_spx_predictions.png', dpi=300)\n",
    "print(\"\\nPlot saved as 'lstm_spx_predictions.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c1ee1-c0f7-44f9-999d-3df0f4490b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 8: FUTURE PREDICTIONS\n",
    "# ============================================\n",
    "\n",
    "def predict_next_days(model, last_sequence, scaler, device, num_days=5):\n",
    "    \"\"\"Predict the next N days\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    current_sequence = last_sequence.clone()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_days):\n",
    "            pred = model(current_sequence.unsqueeze(0))\n",
    "            predictions.append(pred.cpu().item())  # Move to CPU\n",
    "            \n",
    "            current_sequence = torch.cat([\n",
    "                current_sequence[1:],\n",
    "                pred.reshape(1, 1)\n",
    "            ], dim=0)\n",
    "    \n",
    "    predictions_actual = scaler.inverse_transform(\n",
    "        np.array(predictions).reshape(-1, 1)\n",
    "    ).flatten()\n",
    "    \n",
    "    return predictions_actual\n",
    "\n",
    "# Predict next 5 days\n",
    "last_sequence = X_test[-1]\n",
    "future_predictions = predict_next_days(model, last_sequence, scaler, device, num_days=5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FUTURE PREDICTIONS (Next 5 Days)\")\n",
    "print(\"=\"*70)\n",
    "for i, pred in enumerate(future_predictions, 1):\n",
    "    print(f\"Day +{i}: ${pred:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
